[{"content":"","date":null,"permalink":"http://localhost:1313/blog/","section":"Jimmy's Notebook","summary":"","title":"Jimmy's Notebook"},{"content":"","date":null,"permalink":"http://localhost:1313/blog/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"http://localhost:1313/blog/topics/programming/","section":"Topics","summary":"","title":"Programming"},{"content":"","date":null,"permalink":"http://localhost:1313/blog/topics/","section":"Topics","summary":"","title":"Topics"},{"content":"의료 영상 데이터는 주로 DICOM 파일 형태로 저장되는데요,\n이때 수검자 메타데이터가 이미지 상에 함께 나타납니다.\n이를 연구 목적으로 외부로 반출하기 위해서는 이미지 상에 나타나는 개인 정보의 마스킹이 필수적인데요, 이 과정에서 대용량의 데이터를 효율적으로 처리하기 위해 병렬 처리를 고민했습니다.\n이번 글에서는 그 과정을 공유하고자 합니다.\nBrain MRI DICOM 파일 예시 [출처] 1. 상황 설명 #MRI 데이터는 상단 예시와 같이 주로 DICOM 파일 형태로 저장됩니다.\n이때 환자 당 보통 백 장 내외의 사진을 촬영하기 때문에 기간에 따라 대략 수백만 건의 파일을 마스킹해야 하는 상황이 발생합니다.\n2. 문제 정의 #해당 작업은 서버에서 파일을 읽는 I/O Bound 작업과\n파일을 마스킹하는 CPU Bound 작업이 혼합되어 있다고 판단했습니다.\n따라서 ThreadPool을 사용하여 파일을 읽어온 후, 그 결과를 ProcessPool을 사용하여 각 CPU가 마스킹을 수행하는 프로세스를 계획했습니다.\n2-1. 스토리지에서 DICOM 파일 읽기 #MRI 데이터는 PACS 서버에 저장되어 있었기 때문에 데이터를 불러올 때마다 서버에 접근해야 했습니다.\n이때 필연적으로 응답 대기 시간이 발생했는데요,\n읽어올 파일 수가 많을 경우 이러한 대기 시간이 병목으로 작용했습니다.\n이를 해결하기 위해 먼저 멀티스레딩을 떠올렸습니다.\n여러 개의 스레드가 동시에 요청을 보내면, 어떤 스레드가 네트워크 응답을 기다리는 동안 다른 스레드가 다시 새로운 파일을 읽어올 것이므로 응답 대기 시간을 상쇄할 수 있을 것이라고 생각했습니다.\n즉, 동시에 여러 파일을 읽는 데 효과적일 것이라고 판단했습니다.\n2-2. DICOM 파일 마스킹하기 #문제는 멀티스레딩으로 파일을 읽어온 다음이었습니다.\n저는 파이썬의 pydicom 라이브러리를 활용하여 마스킹 작업을 수행했는데요,\n파이썬에서는 GIL(Global Interperter Lock) 때문에 마스킹과 같은 CPU Bound 작업은 멀티스레딩이 큰 효과를 보지 못합니다.\n여기서 GIL이란 파이썬에서 한 번에 하나의 스레드만 실행하도록 하는 일종의 안전장치인데요,\n위와 같이 서버에서 파일을 읽거나, HTTP 요청을 보내는 등 I/O 대기 중에는 GIL이 풀리기 때문에 스레딩 효과를 볼 수 있었죠.\n하지만 CPU 연산 같은 경우에는 GIL이 걸리기 때문에 스레드 기반 병렬화가 효과가 없습니다.\n따라서 아예 프로세스를 늘리는 멀티프로세싱이 필요했습니다.\n이를 통해 읽어온 파일들을 여러 프로세스에 분배하여 작업 속도를 개선할 수 있을 것이라 판단했습니다.\n2-3. 작업 배치 처리하기 #또 한가지 문제는 처리할 파일 수가 매우 많다는 것이었습니다.\n수백만 건의 파일을 처리하고 있는데, 이러한 작업들을 전부 큐에 쌓아두게 된다면 메모리를 GB 단위로 차지하게 되겠죠.\n따라서 OOM 에러를 방지하기 위해 모든 파일을 한번에 제출하는 것이 아닌, 작업을 배치 단위로 나눠서 제출하도록 했습니다.\n3. 결과 및 한계점 #이번 대규모 DICOM 파일 마스킹 사례는 스레드 결과가 프로세스 결과에 전달되는 구조였습니다.\nPACS 서버에서 데이터를 읽어오기 때문에 I/O Bound의 특성이 있었고, 읽어온 파일을 마스킹하는 과정에서 CPU Bound의 특성이 있었기에, 멀티스레딩 그리고 멀티프로세싱 두 방식의 차이 및 적용 방안을 고려하는 계기가 되었습니다.\n나아가 대규모 파일을 처리하기 위해 배치 단위로 작업을 나누고, 메모리를 폭증시키지 않는 선에서 적절한 배치 사이즈를 찾기 위해 여러 테스트를 수행했습니다.\n결과적으로, 이전 방식대로였다면 3개월 이상이 걸릴 작업량을 개발 포함 한달 이내에 완수할 수 있었습니다.\n추가로, python3.13t 에서 GIL을 비활성화하는 옵션이 실험적으로 제공된다고 합니다.\n아직까지는 싱글 스레드에서 성능 하락이 있는 등 한계가 있는 것 같습니다만,\n만약 이번 사례에서 GIL이 없었다면 멀티프로세싱 부분을 스레드 기반으로 단순화할 수 있었겠네요.\n또한, 프로세스를 생성 및 종료하는 비용도 줄였을 테고요.\n몇 가지 한계도 존재하는데요,\n대역폭에 한계가 있어요\nPACS 서버의 대역폭 한계가 존재하기 때문에 멀티스레딩의 효과가 적을 수 있습니다. 프로세스 간 메모리 복제 비용이 발생해요\n멀티프로세싱은 각 프로세스가 독립적인 메모리를 사용합니다. 문제는 DICOM 객체를 각 프로세스에 뿌려야 하는데, 이때 직렬화/역직렬화 비용이 발생한다는 것입니다. 파일의 수가 많고 고해상도일수록 이러한 오버헤드는 커질 것입니다. 리소스 관리가 어려워요\n메모리가 제한된 환경에서 최적의 배치사이즈나 스레드 수, 프로세스 수를 구하기가 어려웠습니다. 디버깅이 복잡해요\n스레드 내부에서 발생한 에러를 바로 확인하기 어려웠습니다. 프로그램이 읽지 못한 파일이 하나 있었는데, 그 원인을 로그를 통해 수동으로 추적해야 했습니다. 로직이 더욱 복잡해지면 디버깅도 더 어려워지겠죠. 향후에는 멀티스레딩 및 멀티프로세싱을 적용할 때 에러를 추적할 방안을 고민해야겠습니다. ","date":"2025년 10월 1일","permalink":"http://localhost:1313/blog/posts/dicom-%ED%8C%8C%EC%9D%BC-%EB%A7%88%EC%8A%A4%ED%82%B9-%EB%B0%A9%EC%95%88/","section":"Posts","summary":"","title":"멀티스레딩과 멀티프로세싱: 대규모 DICOM 파일 마스킹 방안"}]