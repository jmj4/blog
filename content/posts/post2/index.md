+++
date = '2025-12-20T17:24:37+09:00'
draft = false
title = '의정사태에 나타난 언론보도 경향 탐색'
topics = ["NLP"]
layout = "contact"
+++

# LLM으로 본 의정사태 언론 보도
의정사태란 2024년 2월부터 약 1년 반에 걸쳐 이어진  
정부와 의료계 간의 갈등을 말합니다.  
이러한 갈등은 사회 전반으로 확산되었고,  
25년 지금까지도 완전히 해소되었다고 보기는 어렵습니다.  

정치적 이해관계가 복잡하게 얽혀 있는 만큼,  
분석 주제로 다루기에도 까다로웠는데요.  
그래서 이번 글에서는 어떤 주장이 옳은지에 대한 이야기는 잠시 접어두고,  
제가 수행한 LLM 기반 텍스트 분석 작업의 기술적인 내용에 집중해 보려고 합니다.  

---

{{< figure
  src="sign.png"
  alt="안내판 이미지"
  caption="대한의사협회에 다녀왔습니다"
  loading="lazy"
>}}


## 1. 개요

먼저, 이번 연구는 깊이 있는 결론을 도출하기 위한 본 분석이라기보다는,
>해당 주제를 텍스트 분석 기법으로 풀어낼 수 있을까?

를 확인하기 위한 **탐색적 분석**에 가까웠습니다.  

따라서 발표 당시에는 어떤 정량적 결과보다는,  
아래 내용을 위주로 보였습니다.  
- 의정 사태와 관련된 언론 보도 **경향** 확인
- 시도하려는 분석 기법의 직관적인 설명 제시  

본격적인 분석과 해석은 발표 이후에 진행하기로 해서요.  
따라서 이번 글 역시 **중간 점검**에 가깝습니다.  

## 2. 관련 연구

분석 방법을 고민하며 <a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0308065' target='_blank'>해당 연구</a>를 참고했어요.  
이 연구는 간호법 관련 뉴스 기사를 수집한 뒤 **LDA**를 통해 언론이 어떤 이슈를 중심으로 보도했는지를 분석합니다.  
다만 LDA는 잘 알려진 한계들이 있죠.  
- 문서 코퍼스를 Bag of words로 처리
- 단어의 순서나 문맥을 고려하지 않음  

쉽게 말해,
> 전체 문서를 단어별로 잘라 한 가방에 섞어 넣고  
> 어떤 단어가 많이 나오는지를 보는 방식입니다

따라서 의정사태처럼 맥락, 뉘앙스가 중요한 주제에는 바로 적용하기 어렵다고 생각했어요.

## 3. 수행 방안

이러한 한계를 보완하기 위해 BERTopic을 사용했습니다.  
내부적으로 SBERT를 사용하고 있어서 단어 단위가 아닌 문맥을 기반으로 토픽을 생성할 수 있거든요.  
여기에 개별 뉴스의 **감성**을 확인하기 위해  
LLM을 활용한 감성 라벨링을 함께 진행했습니다.

즉, 이번 분석은 다음과 같이 진행됐어요.  
1. 뉴스 기사 스크래핑
2. LLM 기반 감성 라벨링
3. 토픽 모델링

## 4. 실험 방법

### 4.1 데이터 수집
의정사태가 본격적으로 언급되기 시작한 2024년 1월부터 2024년 12월까지의 뉴스기사를 수집했습니다.

검색 조건은 다음과 같이 걸었어요.
- 본문에 "의료" 포함
- 아래 키워들 중 하나 이상 포함
  - 의정사태
  - 의료개혁
  - 의대정원
  - 의대증원

전처리 과정을 거친 후, 총 10,233건의 뉴스 기사를 분석 대상으로 확보했습니다.

### 4.2 감성 라벨링
감성 라벨링에는 <a href='https://arxiv.org/abs/2508.10925' target='_blank'>gpt-oss</a> 20B 모델을 사용했어요.  
25년 8월에 나온 모델인데요, 모델 사이즈가 13 Gb 정도 되서  
Single GPU 환경에서 충분히 구동할 수 있었습니다.  

20B 모델의 성능은 o3‑mini와 비슷한 것으로 보고됐어요.  
25년 12월 기준 <a href='https://lmarena.ai/ko/leaderboard' target='_blank'>LMArena</a>에서 140등 정도 하는 모델입니다.  
아무래도 고성능의 제품을 사용하는 것이 좋겠지만, 
어디까지나 예비 실험이라 모델 부분은 크게 고려하지 않았습니다.

gpt-oss의 아키텍쳐를 간단히 살펴보면
- RMSNorm 사용
- RoPE 적용
- GQA 적용 및 Sliding window attention 사용
- MoE 적용 및 SwiGLU module 사용  

등 기존 LLM들과 구조 면에서 큰 차이는 없는 것으로 보입니다.  

저는 Ollma와 LangChain을 사용해서 작업을 진행했어요.  
그리고 본문에 긍정적 / 부정적인 단어의 포함 여부가 아닌  
기사 전체가 전달하는 뉘앙스를 판단하도록 만들기 위해  
프롬프트에 "공정한 언론인"이란 설명을 주었어요.

결과적으로 10,233건의 뉴스 기사에 대해  
긍정 / 중립 / 부정 감성 라벨링을 수행하는 데 약 8시간이 걸렸습니다.

## 5. 결과

분석은 예상대로 중립 기사가 가장 많았고, 그 다음으로 부정적인 기사가 많았습니다.  
특히 부정적인 기사는 긍정적인 기사보다 두 배 이상 많이 나타났어요.  

아래 그림은 긍정적인 기사를 1점, 중립적인 기사를 0점, 부정적인 기사를 -1점으로 두고  
월별로 평균을 냈을 때 추이를 나타낸 그래프인데요,  
시간이 지남에 따라 감성이 전체적으로 우하향하는 모습을 볼 수 있었습니다.

{{< figure
  src="sent_score.png"
  alt="감성 분석 결과"
  caption="전체 뉴스 감성의 시간적 변화"
  loading="lazy"
>}}

## 6. 결론

해당 발표를 준비하며, 개인적으로 다음과 같은 질문들이 고민이 많이 되었어요.

**1) 뉴스 기사를 분석 대상으로 삼는 것이 과연 적절할까?**  

뉴스는 기본적으로 객관성을 지향합니다.  
그렇다면 감성을 분석하는 것이 의미가 있을까요?  

하지만 동시에 뉴스는 
- 어떤 사실을 선택하고
- 어떤 순서로 배치하며
- 어떤 프레임으로 서술할지를 결정합니다

이 과정 자체가 이미 누군가의 해석의 결과물이라는 점에서,  
감성이 반영되어 있지 않다고 말하기도 어렵다고 생각해요.  

감성 분석 연구를 살펴보면 대부분 댓글이나 사용자 피드백과 같이  
주관적인 감성이 충분히 녹아있는 데이터를 분석 대상으로 삼는 걸 볼 수 있었습니다.  

**2) 6.2 LLM이 판단한 감성은 타당할까?**  

LLM은 부정적인 기사는 판단할 때  
**갈등, 위기, 대립을 강조하는 톤**에 집중합니다.  

그렇다면 이 감성은 기자의 감정일까요,  
아니면 독자가 받아들이게 될 정서일까요?  

또 만약 어떤 독자는 해당 기사를 긍정적으로,  
또 다른 독자는 해당 기사를 부정적으로 받아들인다면  
해당 기사의 감성은 어떻게 평가해야 할까요?

따라서 사회 현상에 관한 문제는  
아직 단일 모델이나 단일 데이터셋으로는 해결하기 어렵다고 느꼈습니다.

---
이번 경험을 통해 실제 현장의 목소리를 들을 수 있는 계기가 되어 좋았어요.  
또한, 텍스트 분석을 통해 지난 1년 반 동안 우리가  
어떤 보도를 반복해서 접해왔는지 기술적으로 살펴볼 수 있었어요.  
특히 LLM은 복잡한 사회 현상을 관찰하는 데 좋은 도구라고 생각합니다.  

다음 번에는 사용하는 모델과 시스템 프롬프트를 더 고도화할 계획이에요.  
특히 gpt-oss는 Reasoning effort를 시스템 프롬프트로 줄 수 있는데요,  
이를 적용해 보는 것도 재밌을 것 같습니다.
