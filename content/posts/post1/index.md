+++
date = 2025-10-01T19:20:00+09:00
draft = false
title = '멀티스레딩과 멀티프로세싱: 대규모 DICOM 파일 마스킹 방안'
topics = ["Programming"]
layout = "contact"
+++

의료 영상 데이터는 주로 DICOM 파일 형태로 저장되는데요,  
이때 수검자 메타데이터가 이미지 상에 함께 나타납니다.  

이를 연구 목적으로 외부로 반출하기 위해서는 이미지 상에 나타나는 개인 정보의 마스킹이 필수적인데요, 이 과정에서 대용량의 데이터를 효율적으로 처리하기 위해 병렬 처리를 고민했습니다.

이번 글에서는 그 과정을 공유하고자 합니다.  

---

{{< figure
  src="dicom_example.png"
  alt="Brain MRI DICOM 예시 이미지"
  caption="Brain MRI DICOM 파일 예시 <a href='https://www.magnetomworld.siemens-healthineers.com/korean-dicom-image-gallery' target='_blank'>[출처]</a>"
  loading="lazy"
>}}

## 1. 상황 설명

MRI 데이터는 상단 예시와 같이 주로 DICOM 파일 형태로 저장됩니다.  
이때 환자 당 보통 백 장 내외의 사진을 촬영하기 때문에 기간에 따라 대략 **수백만 건**의 파일을 마스킹해야 하는 상황이 발생합니다.

---

## 2. 문제 정의

해당 작업은 서버에서 파일을 읽는 **I/O Bound** 작업과  
파일을 마스킹하는 **CPU Bound** 작업이 혼합되어 있다고 판단했습니다.  

따라서 ThreadPool을 사용하여 파일을 읽어온 후, 그 결과를 ProcessPool을 사용하여 각 CPU가 마스킹을 수행하는 프로세스를 계획했습니다.

### 2-1. 스토리지에서 DICOM 파일 읽기

MRI 데이터는 PACS 서버에 저장되어 있었기 때문에 데이터를 불러올 때마다 서버에 접근해야 했습니다.  
이때 필연적으로 응답 대기 시간이 발생했는데요,  
읽어올 파일 수가 많을 경우 이러한 대기 시간이 병목으로 작용했습니다.

이를 해결하기 위해 먼저 **멀티스레딩**을 떠올렸습니다.  
여러 개의 스레드가 동시에 요청을 보내면, 어떤 스레드가 네트워크 응답을 기다리는 동안 다른 스레드가 다시 새로운 파일을 읽어올 것이므로 응답 대기 시간을 상쇄할 수 있을 것이라고 생각했습니다.  
즉, **동시에 여러 파일을 읽는** 데 효과적일 것이라고 판단했습니다.

### 2-2. DICOM 파일 마스킹하기

문제는 멀티스레딩으로 파일을 읽어온 다음이었습니다.  
저는 파이썬의 pydicom 라이브러리를 활용하여 마스킹 작업을 수행했는데요,  
파이썬에서는 **GIL(Global Interperter Lock)** 때문에 마스킹과 같은 CPU Bound 작업은 멀티스레딩이 큰 효과를 보지 못합니다.

여기서 GIL이란 파이썬에서 한 번에 하나의 스레드만 실행하도록 하는 일종의 안전장치인데요,  
위와 같이 서버에서 파일을 읽거나, HTTP 요청을 보내는 등 I/O 대기 중에는 GIL이 풀리기 때문에 스레딩 효과를 볼 수 있었죠.  
하지만 CPU 연산 같은 경우에는 GIL이 걸리기 때문에 스레드 기반 병렬화가 효과가 없습니다.  
따라서 아예 프로세스를 늘리는 **멀티프로세싱**이 필요했습니다.  
이를 통해 **읽어온 파일들을 여러 프로세스에 분배**하여 작업 속도를 개선할 수 있을 것이라 판단했습니다.

### 2-3. 작업 배치 처리하기

또 한가지 문제는 처리할 파일 수가 매우 많다는 것이었습니다.  
수백만 건의 파일을 처리하고 있는데, 이러한 작업들을 전부 큐에 쌓아두게 된다면 메모리를 GB 단위로 차지하게 되겠죠.  
따라서 OOM 에러를 방지하기 위해 모든 파일을 한번에 제출하는 것이 아닌, 작업을 **배치 단위로 나눠서 제출**하도록 했습니다.

---

## 3. 결과 및 한계점

이번 대규모 DICOM 파일 마스킹 사례는 **스레드 결과가 프로세스 결과에 전달**되는 구조였습니다.  
PACS 서버에서 데이터를 읽어오기 때문에 I/O Bound의 특성이 있었고, 읽어온 파일을 마스킹하는 과정에서 CPU Bound의 특성이 있었기에, 멀티스레딩 그리고 멀티프로세싱 두 방식의 차이 및 적용 방안을 고려하는 계기가 되었습니다.

나아가 대규모 파일을 처리하기 위해 배치 단위로 작업을 나누고, 메모리를 폭증시키지 않는 선에서 적절한 배치 사이즈를 찾기 위해 여러 테스트를 수행했습니다.

결과적으로, 이전 방식대로였다면 3개월 이상이 걸릴 작업량을 개발 포함 한달 이내에 완수할 수 있었습니다.

몇 가지 한계도 존재하는데요,  
- **대역폭에 한계가 있어요**  
    PACS 서버의 대역폭이 이미 포화 상태라면 멀티스레딩의 효과가 적을 수 있습니다.  
- **프로세스 간 메모리 복제 비용이 발생해요**  
    멀티프로세싱은 각 프로세스가 독립적인 메모리를 사용합니다. 현재는 서버로부터 파일을 읽은 뒤, DICOM 파일 객체를 각 프로세스에 전달하고 있는데, 이 과정에서 직렬화/역직렬화 비용이 발생합니다. 파일의 수가 많고 고해상도일수록 이러한 오버헤드는 커질 것입니다.  
- **리소스 관리가 어려워요**  
    메모리가 제한된 환경에서 최적의 처리 단위 크기나 스레드, 프로세스 수를 구하기가 어려웠습니다.

추가로, python3.13t 에서 GIL을 비활성화하는 옵션이 *실험적으로* 제공된다고 합니다.  
아직까지는 싱글 스레드에서 성능 하락이 있는 등 한계가 있는 것 같습니다만, 만약 이번 사례에서 GIL이 없었다면 멀티프로세싱 부분을 스레드 기반으로 단순화할 수 있었겠네요.  
또한, 프로세스를 생성 및 종료하는 비용도 줄였을 테고요.  
향후에는 병렬 처리 효율을 높이는 방안을 고민해 봐야겠습니다.